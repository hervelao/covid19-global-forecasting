{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the libraries\n",
    "\n",
    "# for data manipulation & linear algebrea\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# import plotly\n",
    "# import plotly.graph_objs as go\n",
    "%config InlineBackend.figure_format = 'retina' # vs 'svg'/'png'\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "# for machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "\n",
    "# Other libraries\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# Path\n",
    "import sys\n",
    "sys.path.append('/Users/herve/code/hervelao/covid19-global-forecasting')\n",
    "# from pathlib import Path\n",
    "# data_dir = Path('/Users/herve/code/hervelao/covid19-global-forecasting')\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "from covid19.data import COVID19\n",
    "\n",
    "data = COVID19().get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 1. Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = data['submission']\n",
    "test = data['test']\n",
    "train = data['train']\n",
    "display(train.head(5))\n",
    "display(train.describe())\n",
    "print(\"Number of Country/Region: \", train['Country/Region'].nunique())\n",
    "print(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\n",
    "print(\"Countries with Province/State informed: \", train[train['Province/State'].isna()==False]['Country/Region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_country = train.groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country = train.groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date = train.groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date = train.groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date = confirmed_total_date.join(fatalities_total_date)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\n",
    "\n",
    "total_date.plot(ax=ax1)\n",
    "ax1.set_title(\"Global confirmed cases\", size=13)\n",
    "ax1.set_ylabel(\"Number of cases\", size=13)\n",
    "ax1.set_xlabel(\"Date\", size=13)\n",
    "\n",
    "fatalities_total_date.plot(ax=ax2, color='orange')\n",
    "ax2.set_title(\"Global deceased cases\", size=13)\n",
    "ax2.set_ylabel(\"Number of cases\", size=13)\n",
    "ax2.set_xlabel(\"Date\", size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_country_noChina = train[train['Country/Region']!='China'].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_noChina = train[train['Country/Region']!='China'].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_noChina = train[train['Country/Region']!='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_noChina = train[train['Country/Region']!='China'].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "total_date_noChina.plot(ax=ax1)\n",
    "ax1.set_title(\"Global confirmed cases excluding China\", size=13)\n",
    "ax1.set_ylabel(\"Number of cases\", size=13)\n",
    "ax1.set_xlabel(\"Date\", size=13)\n",
    "fatalities_total_date_noChina.plot(ax=ax2, color='orange')\n",
    "ax2.set_title(\"Global deceased cases excluding China\", size=13)\n",
    "ax2.set_ylabel(\"Number of cases\", size=13)\n",
    "ax2.set_xlabel(\"Date\", size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_country_China = train[train['Country/Region']=='China'].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_China = train[train['Country/Region']=='China'].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_China = train[train['Country/Region']=='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_China = train[train['Country/Region']=='China'].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "total_date_China.plot(ax=ax1)\n",
    "ax1.set_title(\"China confirmed cases\", size=13)\n",
    "ax1.set_ylabel(\"Number of cases\", size=13)\n",
    "ax1.set_xlabel(\"Date\", size=13)\n",
    "fatalities_total_date_China.plot(ax=ax2, color='orange')\n",
    "ax2.set_title(\"China deceased cases\", size=13)\n",
    "ax2.set_ylabel(\"Number of cases\", size=13)\n",
    "ax2.set_xlabel(\"Date\", size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_country_Italy = train[train['Country/Region']=='Italy'].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Italy = train[train['Country/Region']=='Italy'].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Italy = train[train['Country/Region']=='Italy'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Italy = train[train['Country/Region']=='Italy'].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n",
    "\n",
    "confirmed_country_Spain = train[train['Country/Region']=='Spain'].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Spain = train[train['Country/Region']=='Spain'].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Spain = train[train['Country/Region']=='Spain'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Spain = train[train['Country/Region']=='Spain'].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n",
    "\n",
    "confirmed_country_UK = train[train['Country/Region']=='United Kingdom'].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_UK = train[train['Country/Region']=='United Kingdom'].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_UK = train[train['Country/Region']=='United Kingdom'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_UK = train[train['Country/Region']=='United Kingdom'].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_UK = confirmed_total_date_UK.join(fatalities_total_date_UK)\n",
    "\n",
    "confirmed_country_Australia = train[train['Country/Region']=='Australia'].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Australia = train[train['Country/Region']=='Australia'].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Australia = train[train['Country/Region']=='Australia'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Australia = train[train['Country/Region']=='Australia'].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n",
    "\n",
    "confirmed_country_Singapore = train[train['Country/Region']=='Singapore'].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Singapore = train[train['Country/Region']=='Singapore'].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Singapore = train[train['Country/Region']=='Singapore'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Singapore = train[train['Country/Region']=='Singapore'].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "total_date_Italy.plot(ax=plt.gca(), title='Italy')\n",
    "plt.ylabel(\"Confirmed infection cases\", size=13)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "total_date_Spain.plot(ax=plt.gca(), title='Spain')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "total_date_UK.plot(ax=plt.gca(), title='United Kingdom')\n",
    "plt.ylabel(\"Confirmed infection cases\", size=13)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "total_date_Singapore.plot(ax=plt.gca(), title='Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_italy = 60486683.\n",
    "pop_spain = 46749696.\n",
    "pop_UK = 67784927.\n",
    "pop_singapore = 5837230.\n",
    "\n",
    "total_date_Italy.ConfirmedCases = total_date_Italy.ConfirmedCases/pop_italy*100.\n",
    "total_date_Italy.Fatalities = total_date_Italy.ConfirmedCases/pop_italy*100.\n",
    "total_date_Spain.ConfirmedCases = total_date_Spain.ConfirmedCases/pop_spain*100.\n",
    "total_date_Spain.Fatalities = total_date_Spain.ConfirmedCases/pop_spain*100.\n",
    "total_date_UK.ConfirmedCases = total_date_UK.ConfirmedCases/pop_UK*100.\n",
    "total_date_UK.Fatalities = total_date_UK.ConfirmedCases/pop_UK*100.\n",
    "total_date_Singapore.ConfirmedCases = total_date_Singapore.ConfirmedCases/pop_singapore*100.\n",
    "total_date_Singapore.Fatalities = total_date_Singapore.ConfirmedCases/pop_singapore*100.\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "total_date_Italy.ConfirmedCases.plot(ax=plt.gca(), title='Italy')\n",
    "plt.ylabel(\"Fraction of population infected\")\n",
    "plt.ylim(0, 0.06)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "total_date_Spain.ConfirmedCases.plot(ax=plt.gca(), title='Spain')\n",
    "plt.ylim(0, 0.06)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "total_date_UK.ConfirmedCases.plot(ax=plt.gca(), title='United Kingdom')\n",
    "plt.ylabel(\"Fraction of population infected\")\n",
    "plt.ylim(0, 0.005)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "total_date_Singapore.ConfirmedCases.plot(ax=plt.gca(), title='Singapore')\n",
    "plt.ylim(0, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_country_Italy = train[(train['Country/Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Italy = train[(train['Country/Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Italy = train[(train['Country/Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Italy = train[(train['Country/Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n",
    "\n",
    "confirmed_country_Spain = train[(train['Country/Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Spain = train[(train['Country/Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Spain = train[(train['Country/Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Spain = train[(train['Country/Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n",
    "\n",
    "confirmed_country_UK = train[(train['Country/Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_UK = train[(train['Country/Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_UK = train[(train['Country/Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_UK = train[(train['Country/Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_UK = confirmed_total_date_UK.join(fatalities_total_date_UK)\n",
    "\n",
    "confirmed_country_Australia = train[(train['Country/Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Australia = train[(train['Country/Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Australia = train[(train['Country/Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Australia = train[(train['Country/Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n",
    "\n",
    "confirmed_country_Singapore = train[(train['Country/Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_country_Singapore = train[(train['Country/Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\n",
    "confirmed_total_date_Singapore = train[(train['Country/Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\n",
    "fatalities_total_date_Singapore = train[(train['Country/Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\n",
    "total_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n",
    "\n",
    "italy = [i for i in total_date_Italy.ConfirmedCases['sum'].values]\n",
    "italy_30 = italy[0:50] \n",
    "spain = [i for i in total_date_Spain.ConfirmedCases['sum'].values]\n",
    "spain_30 = spain[0:50] \n",
    "UK = [i for i in total_date_UK.ConfirmedCases['sum'].values]\n",
    "UK_30 = UK[0:50] \n",
    "singapore = [i for i in total_date_Singapore.ConfirmedCases['sum'].values]\n",
    "singapore_30 = singapore[0:50] \n",
    "\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(italy_30)\n",
    "plt.plot(spain_30)\n",
    "plt.plot(UK_30)\n",
    "plt.plot(singapore_30)\n",
    "plt.legend([\"Italy\", \"Spain\", \"UK\", \"Singapore\"], loc='upper left')\n",
    "plt.title(\"COVID-19 infections from the first confirmed case\", size=15)\n",
    "plt.xlabel(\"Days\", size=13)\n",
    "plt.ylabel(\"Infected cases\", size=13)\n",
    "plt.ylim(0, 60000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 2. Data enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and test, exclude overlap\n",
    "dates_overlap = ['2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18',\n",
    "                 '2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23']\n",
    "train2 = train.loc[~train['Date'].isin(dates_overlap)]\n",
    "all_data = pd.concat([train2, test], axis = 0, sort=False)\n",
    "\n",
    "# Double check that there are no informed ConfirmedCases and Fatalities after 2020-03-11\n",
    "all_data.loc[all_data['Date'] >= '2020-03-12', 'ConfirmedCases'] = np.nan\n",
    "all_data.loc[all_data['Date'] >= '2020-03-12', 'Fatalities'] = np.nan\n",
    "all_data['Date'] = pd.to_datetime(all_data['Date'])\n",
    "\n",
    "# Create date columns\n",
    "le = preprocessing.LabelEncoder()\n",
    "all_data['Day_num'] = le.fit_transform(all_data.Date)\n",
    "all_data['Day'] = all_data['Date'].dt.day\n",
    "all_data['Month'] = all_data['Date'].dt.month\n",
    "all_data['Year'] = all_data['Date'].dt.year\n",
    "\n",
    "# Fill null values given that we merged train-test datasets\n",
    "all_data['Province/State'] = all_data['Province/State'].cat.add_categories('None')\n",
    "all_data['Province/State'].fillna(\"None\", inplace=True)\n",
    "all_data['ConfirmedCases'].fillna(0, inplace=True)\n",
    "all_data['Fatalities'].fillna(0, inplace=True)\n",
    "all_data['Id'].fillna(-1, inplace=True)\n",
    "all_data['ForecastId'].fillna(-1, inplace=True)\n",
    "\n",
    "# Aruba has no Lat nor Long. Inform it manually\n",
    "all_data.loc[all_data['Lat'].isna()==True, 'Lat'] = 12.510052\n",
    "all_data.loc[all_data['Long'].isna()==True, 'Long'] = -70.009354\n",
    "\n",
    "display(all_data)\n",
    "display(all_data.loc[all_data['Date'] == '2020-03-12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings_count = {col:all_data[col].isnull().sum() for col in all_data.columns}\n",
    "missings = pd.DataFrame.from_dict(missings_count, orient='index')\n",
    "print(missings.nlargest(30, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trend(df, lag_list, column):\n",
    "    for lag in lag_list:\n",
    "        trend_column_lag = \"Trend_\" + column + \"_\" + str(lag)\n",
    "        df[trend_column_lag] = (df[column]-df[column].shift(lag, fill_value=-999))/df[column].shift(lag, fill_value=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_lag(df, lag_list, column):\n",
    "    for lag in lag_list:\n",
    "        column_lag = column + \"_\" + str(lag)\n",
    "        df[column_lag] = df[column].shift(lag, fill_value=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "all_data = calculate_lag(all_data, range(1,7), 'ConfirmedCases')\n",
    "all_data = calculate_lag(all_data, range(1,7), 'Fatalities')\n",
    "all_data = calculate_trend(all_data, range(1,7), 'ConfirmedCases')\n",
    "all_data = calculate_trend(all_data, range(1,7), 'Fatalities')\n",
    "all_data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "all_data.fillna(0, inplace=True)\n",
    "print(\"Time spent: \", time.time()-ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load countries data file\n",
    "world_population = pd.read_csv(\"../data/additional_csv/population_by_country_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select desired columns and rename some of them\n",
    "world_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/KmÂ²)', 'Land Area (KmÂ²)', 'Med. Age', 'Urban Pop %']]\n",
    "world_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace United States by US\n",
    "world_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the % character from Urban Pop values\n",
    "world_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\n",
    "world_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\n",
    "world_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\n",
    "world_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\n",
    "world_population['Med Age'] = world_population['Med Age'].astype('int16')\n",
    "\n",
    "print(\"Cleaned country details dataset\")\n",
    "display(world_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\n",
    "print(\"Joined dataset\")\n",
    "all_data = all_data.merge(world_population, left_on='Country/Region', right_on='Country (or dependency)', how='left')\n",
    "all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\n",
    "display(all_data)\n",
    "print(\"Encoded dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode countries and provinces. Save dictionary for exploration purposes\n",
    "all_data.drop('Country (or dependency)', inplace=True, axis=1)\n",
    "all_data['Country/Region'] = le.fit_transform(all_data['Country/Region'])\n",
    "number_c = all_data['Country/Region']\n",
    "countries = le.inverse_transform(all_data['Country/Region'])\n",
    "country_dict = dict(zip(countries, number_c)) \n",
    "all_data['Province/State'] = le.fit_transform(all_data['Province/State'])\n",
    "number_p = all_data['Province/State']\n",
    "province = le.inverse_transform(all_data['Province/State'])\n",
    "province_dict = dict(zip(province, number_p)) \n",
    "display(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for 1 country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "# Day_num = 38 is March 1st\n",
    "y1 = all_data[(all_data['Lat']==40.0) & (all_data['Long']==-4.0) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']]\n",
    "x1 = range(0, len(y1))\n",
    "ax1.plot(x1, y1, 'bo--')\n",
    "ax1.set_title(\"Spain ConfirmedCases between days 39 and 49 (last 10 days)\")\n",
    "ax1.set_xlabel(\"Days\")\n",
    "ax1.set_ylabel(\"ConfirmedCases\")\n",
    "\n",
    "y2 = all_data[(all_data['Lat']==40.0) & (all_data['Long']==-4.0) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']].apply(lambda x: np.log(x))\n",
    "x2 = range(0, len(y2))\n",
    "ax2.plot(x2, y2, 'bo--')\n",
    "ax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49 (last 10 days)\")\n",
    "ax2.set_xlabel(\"Days\")\n",
    "ax2.set_ylabel(\"Log ConfirmedCases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter selected features\n",
    "data = all_data.copy()\n",
    "features = ['Id', 'ForecastId', 'Country/Region', 'Province/State', 'ConfirmedCases', 'Fatalities', \n",
    "       'Day_num', 'Day', 'Month', 'Year', 'Long', 'Lat']\n",
    "data = data[features]\n",
    "\n",
    "# Apply log transformation to all ConfirmedCases and Fatalities columns, except for trends\n",
    "data[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\n",
    "data[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log(x))\n",
    "\n",
    "# Replace infinites\n",
    "data.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test\n",
    "def split_data(data):\n",
    "    \n",
    "    # Train set\n",
    "    x_train = data[data.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n",
    "    y_train_1 = data[data.ForecastId == -1]['ConfirmedCases']\n",
    "    y_train_2 = data[data.ForecastId == -1]['Fatalities']\n",
    "\n",
    "    # Test set\n",
    "    x_test = data[data.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n",
    "\n",
    "    # Clean Id columns and keep ForecastId as index\n",
    "    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n",
    "    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n",
    "    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n",
    "    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n",
    "    \n",
    "    return x_train, y_train_1, y_train_2, x_test\n",
    "\n",
    "\n",
    "# Linear regression model\n",
    "def lin_reg(X_train, Y_train, X_test):\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, Y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test)\n",
    "    \n",
    "    return regr, y_pred\n",
    "\n",
    "\n",
    "# Submission function\n",
    "def get_submission(df):\n",
    "    \n",
    "    prediction_1 = df['Predicted_ConfirmedCases']\n",
    "    prediction_2 = df['Predicted_Fatalities']\n",
    "\n",
    "    # Submit predictions\n",
    "    prediction_1 = [int(item) for item in list(map(round, prediction_1))]\n",
    "    prediction_2 = [int(item) for item in list(map(round, prediction_2))]\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        \"ForecastId\": df['ForecastId'].astype('int32'), \n",
    "        \"ConfirmedCases\": prediction_1, \n",
    "        \"Fatalities\": prediction_2\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Spain, run the Linear Regression workflow\n",
    "country_name = \"Spain\"\n",
    "day_start = 39\n",
    "data_country = data[data['Country/Region']==country_dict[country_name]]\n",
    "data_country = data_country.loc[data_country['Day_num']>=day_start]\n",
    "X_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\n",
    "model, pred = lin_reg(X_train, Y_train_1, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with both real cases and predictions (predictions starting on March 12th)\n",
    "X_train_check = X_train.copy()\n",
    "X_train_check['Target'] = Y_train_1\n",
    "\n",
    "X_test_check = X_test.copy()\n",
    "X_test_check['Target'] = pred\n",
    "\n",
    "X_final_check = pd.concat([X_train_check, X_test_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select train (real) data from March 1 to March 22nd\n",
    "dates_list = ['2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', \n",
    "                 '2020-03-10', '2020-03-11','2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18',\n",
    "                 '2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23']\n",
    "\n",
    "# Select predictions from March 1st to March 22nd\n",
    "predicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\n",
    "real_data = train.loc[(train['Country/Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n",
    "dates_list_num = list(range(0,len(dates_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "ax1.plot(dates_list_num, np.exp(predicted_data))\n",
    "ax1.plot(dates_list_num, real_data)\n",
    "ax1.axvline(10, linewidth=2, ls = ':', color='grey', alpha=0.5)\n",
    "ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n",
    "ax1.set_xlabel(\"Day count (from March 1st to March 22nd)\")\n",
    "ax1.set_ylabel(\"Confirmed Cases\")\n",
    "\n",
    "ax2.plot(dates_list_num, predicted_data)\n",
    "ax2.plot(dates_list_num, np.log(real_data))\n",
    "ax2.axvline(10, linewidth=2, ls = ':', color='grey', alpha=0.5)\n",
    "ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n",
    "ax2.set_xlabel(\"Day count (from March 1st to March 22nd)\")\n",
    "ax2.set_ylabel(\"Log Confirmed Cases\")\n",
    "\n",
    "plt.suptitle((\"ConfirmedCases predictions based on Logistic Regression for \"+country_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Logistic Regression for all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "day_start = 39\n",
    "data2 = data.loc[data.Day_num >= day_start]\n",
    "\n",
    "# Set the dataframe where we will update the predictions\n",
    "data_pred = data[data.ForecastId != -1][['Country/Region', 'Province/State', 'Day_num', 'ForecastId']]\n",
    "data_pred = data_pred.loc[data_pred['Day_num']>=day_start]\n",
    "data_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\n",
    "data_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n",
    "    \n",
    "print(\"Currently running Logistic Regression for all countries\")\n",
    "\n",
    "# Main loop for countries\n",
    "for c in data2['Country/Region'].unique():\n",
    "    \n",
    "    # List of provinces\n",
    "    provinces_list = data2[data2['Country/Region']==c]['Province/State'].unique()\n",
    "        \n",
    "    # If the country has several Province/State informed\n",
    "    if len(provinces_list)>1:\n",
    "        for p in provinces_list:\n",
    "            data_cp = data2[(data2['Country/Region']==c) & (data2['Province/State']==p)]\n",
    "            X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n",
    "            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "            data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n",
    "            data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "    # No Province/State informed\n",
    "    else:\n",
    "        data_c = data2[(data2['Country/Region']==c)]\n",
    "        X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n",
    "        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "        data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n",
    "        data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "# Aplly exponential transf. and clean potential infinites due to final numerical precision\n",
    "data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.exp(x))\n",
    "data_pred.replace([np.inf, -np.inf], 0, inplace=True) \n",
    "\n",
    "get_submission(data_pred)\n",
    "\n",
    "print(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below if we keep all data for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "# Set the dataframe where we will update the predictions\n",
    "data_pred = data[data.ForecastId != -1][['Country/Region', 'Province/State', 'Day_num', 'ForecastId']]\n",
    "data_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\n",
    "data_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n",
    "how_many_days = test.Date.nunique()\n",
    "    \n",
    "print(\"Currently running Logistic Regression for all countries\")\n",
    "\n",
    "# Main loop for countries\n",
    "for c in data['Country/Region'].unique():\n",
    "    \n",
    "    # List of provinces\n",
    "    provinces_list = data2[data2['Country/Region']==c]['Province/State'].unique()\n",
    "        \n",
    "    # If the country has several Province/State informed\n",
    "    if len(provinces_list)>1:\n",
    "        \n",
    "        for p in provinces_list:\n",
    "            # Only fit starting from the first confirmed case in the country\n",
    "            train_countries_no0 = data.loc[(data['Country/Region']==c) & (data['Province/State']==p) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n",
    "            test_countries_no0 = data.loc[(data['Country/Region']==c) & (data['Province/State']==p) &  (data.ForecastId!=-1)]\n",
    "            data2 = pd.concat([train_countries_no0, test_countries_no0])\n",
    "\n",
    "            # If there are no previous cases, predict 0\n",
    "            if len(train_countries_no0) == 0:\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data_pred['Province/State']==p)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data_pred['Province/State']==p)), 'Predicted_Fatalities'] = [0]*how_many_days\n",
    "                \n",
    "            # Else run LinReg\n",
    "            else: \n",
    "                data_cp = data2[(data2['Country/Region']==c) & (data2['Province/State']==p)]\n",
    "                X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n",
    "                model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "                model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "    # No Province/State informed\n",
    "    else:\n",
    "        # Only fit starting from the first confirmed case in the country\n",
    "        train_countries_no0 = data.loc[(data['Country/Region']==c) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n",
    "        test_countries_no0 = data.loc[(data['Country/Region']==c) &  (data.ForecastId!=-1)]\n",
    "        data2 = pd.concat([train_countries_no0, test_countries_no0])\n",
    "\n",
    "        # If there are no previous cases, predict 0\n",
    "        if len(train_countries_no0) == 0:\n",
    "            data_pred.loc[((data_pred['Country/Region']==c)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n",
    "            data_pred.loc[((data_pred['Country/Region']==c)), 'Predicted_Fatalities'] = [0]*how_many_days\n",
    "        \n",
    "        # Else, run LinReg\n",
    "        else:\n",
    "            data_c = data2[(data2['Country/Region']==c)]\n",
    "            X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n",
    "            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "            data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n",
    "            data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "# Aplly exponential transf. and clean potential infinites due to final numerical precision\n",
    "data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.exp(x))\n",
    "data_pred.replace([np.inf, -np.inf], 0, inplace=True) \n",
    "\n",
    "#get_submission(index, data_pred)\n",
    "\n",
    "print(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New split function, for one forecast day\n",
    "def split_data_one_day(data, d):\n",
    "    \n",
    "    #Train\n",
    "    x_train = data[data.Day_num<d]\n",
    "    y_train_1 = x_train.ConfirmedCases\n",
    "    y_train_2 = x_train.Fatalities\n",
    "    x_train.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n",
    "    \n",
    "    #Test\n",
    "    x_test = data[data.Day_num==d]\n",
    "    x_test.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n",
    "    \n",
    "    # Clean Id columns and keep ForecastId as index\n",
    "    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n",
    "    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n",
    "    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n",
    "    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n",
    "    \n",
    "    return x_train, y_train_1, y_train_2, x_test\n",
    "\n",
    "\n",
    "def plot_real_vs_prediction_country(data, train, country_name, day_start, dates_list):\n",
    "\n",
    "    day_start = 39\n",
    "    # Select predictions from March 1st to March 22nd\n",
    "    predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].ConfirmedCases\n",
    "    real_data = train.loc[(train['Country/Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n",
    "    dates_list_num = list(range(0,len(dates_list)))\n",
    "\n",
    "    # Plot results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "    ax1.plot(dates_list_num, np.exp(predicted_data))\n",
    "    ax1.plot(dates_list_num, real_data)\n",
    "    ax1.axvline(10, linewidth=2, ls = ':', color='grey', alpha=0.5)\n",
    "    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n",
    "    ax1.set_xlabel(\"Day count (starting on March 1st)\")\n",
    "    ax1.set_ylabel(\"Confirmed Cases\")\n",
    "\n",
    "    ax2.plot(dates_list_num, predicted_data)\n",
    "    ax2.plot(dates_list_num, np.log(real_data))\n",
    "    ax2.axvline(10, linewidth=2, ls = ':', color='grey', alpha=0.5)\n",
    "    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n",
    "    ax2.set_xlabel(\"Day count (starting on March 1st)\")\n",
    "    ax2.set_ylabel(\"Log Confirmed Cases\")\n",
    "\n",
    "    plt.suptitle((\"ConfirmedCases predictions based on Logistic Regression for \"+country_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "# Inputs\n",
    "country_name = \"France\"\n",
    "day_start = 35 \n",
    "lag_size = 30\n",
    "\n",
    "# Filter country and features from all_data (dataset without data leaking)\n",
    "data = all_data.copy()\n",
    "features = ['Id', 'Province/State', 'Country/Region', 'Lat', 'Long', \n",
    "       'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num', 'Day', 'Month',\n",
    "       'Year', 'ConfirmedCases_1', 'ConfirmedCases_2', 'ConfirmedCases_3',\n",
    "       'ConfirmedCases_4', 'ConfirmedCases_5', 'ConfirmedCases_6',\n",
    "       'Fatalities_1', 'Fatalities_2', 'Fatalities_3', 'Fatalities_4',\n",
    "       'Fatalities_5', 'Fatalities_6']\n",
    "data = data[features]\n",
    "\n",
    "# Select country an data start (all days)\n",
    "data = data[data['Country/Region']==country_dict[country_name]]\n",
    "data = data.loc[data['Day_num']>=day_start]\n",
    "\n",
    "# Lags\n",
    "data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n",
    "data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n",
    "\n",
    "# Apply log transformation\n",
    "data[['ConfirmedCases', 'Fatalities', 'ConfirmedCases_1', 'ConfirmedCases_2', 'ConfirmedCases_3',\n",
    "       'ConfirmedCases_4', 'ConfirmedCases_5', 'ConfirmedCases_6',\n",
    "       'Fatalities_1', 'Fatalities_2', 'Fatalities_3', 'Fatalities_4',\n",
    "       'Fatalities_5', 'Fatalities_6']] = data[['ConfirmedCases', 'Fatalities', 'ConfirmedCases_1', 'ConfirmedCases_2', 'ConfirmedCases_3',\n",
    "       'ConfirmedCases_4', 'ConfirmedCases_5', 'ConfirmedCases_6',\n",
    "       'Fatalities_1', 'Fatalities_2', 'Fatalities_3', 'Fatalities_4',\n",
    "       'Fatalities_5', 'Fatalities_6']].apply(lambda x: np.log(x))\n",
    "data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Start/end of forecast\n",
    "start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n",
    "end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n",
    "\n",
    "for d in list(range(start_fcst, end_fcst+1)):\n",
    "    X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d)\n",
    "    model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "    data.loc[(data['Country/Region']==country_dict[country_name]) \n",
    "             & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n",
    "    model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "    data.loc[(data['Country/Region']==country_dict[country_name]) \n",
    "             & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n",
    "    \n",
    "    # Recompute lags \n",
    "    data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n",
    "    data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n",
    "    data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    data.fillna(0, inplace=True)\n",
    "    \n",
    "print(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")\n",
    "\n",
    "\n",
    "dates_list = ['2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', \n",
    "                     '2020-03-10', '2020-03-11','2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18',\n",
    "                     '2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23']\n",
    "plot_real_vs_prediction_country(data, train, country_name, 39, dates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "\n",
    "# Set the dataframe where we will update the predictions\n",
    "data_pred = data[data.ForecastId != -1][['Country/Region', 'Province/State', 'Day_num', 'ForecastId']]\n",
    "data_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\n",
    "data_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n",
    "how_many_days = test.Date.nunique()\n",
    "    \n",
    "print(\"Currently running Logistic Regression with lags for all countries\")\n",
    "\n",
    "# Main loop for countries\n",
    "for c in data['Country/Region'].unique():\n",
    "    \n",
    "    # List of provinces\n",
    "    provinces_list = data2[data2['Country/Region']==c]['Province/State'].unique()\n",
    "        \n",
    "    # If the country has several Province/State informed\n",
    "    if len(provinces_list)>1:\n",
    "        \n",
    "        for p in provinces_list:\n",
    "            # Only fit starting from the first confirmed case in the country\n",
    "            train_countries_no0 = data.loc[(data['Country/Region']==c) & (data['Province/State']==p) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n",
    "            test_countries_no0 = data.loc[(data['Country/Region']==c) & (data['Province/State']==p) &  (data.ForecastId!=-1)]\n",
    "            data2 = pd.concat([train_countries_no0, test_countries_no0])\n",
    "\n",
    "            # If there are no previous cases, predict 0\n",
    "            if len(train_countries_no0) == 0:\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data_pred['Province/State']==p)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data_pred['Province/State']==p)), 'Predicted_Fatalities'] = [0]*how_many_days\n",
    "                \n",
    "            # Else run LinReg\n",
    "            else: \n",
    "                data_cp = data2[(data2['Country/Region']==c) & (data2['Province/State']==p)]\n",
    "                X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n",
    "                model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "                model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n",
    "                data_pred.loc[((data_pred['Country/Region']==c) & (data2['Province/State']==p)), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "    # No Province/State informed\n",
    "    else:\n",
    "        # Only fit starting from the first confirmed case in the country\n",
    "        train_countries_no0 = data.loc[(data['Country/Region']==c) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n",
    "        test_countries_no0 = data.loc[(data['Country/Region']==c) &  (data.ForecastId!=-1)]\n",
    "        data2 = pd.concat([train_countries_no0, test_countries_no0])\n",
    "\n",
    "        # If there are no previous cases, predict 0\n",
    "        if len(train_countries_no0) == 0:\n",
    "            data_pred.loc[((data_pred['Country/Region']==c)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n",
    "            data_pred.loc[((data_pred['Country/Region']==c)), 'Predicted_Fatalities'] = [0]*how_many_days\n",
    "        \n",
    "        # Else, run LinReg\n",
    "        else:\n",
    "            data_c = data2[(data2['Country/Region']==c)]\n",
    "            X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n",
    "            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "            data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n",
    "            data_pred.loc[(data_pred['Country/Region']==c), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "# Aplly exponential transf. and clean potential infinites due to final numerical precision\n",
    "data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.exp(x))\n",
    "data_pred.replace([np.inf, -np.inf], 0, inplace=True) \n",
    "\n",
    "#get_submission(index, data_pred_2)\n",
    "\n",
    "print(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('lewagon': venv)",
   "language": "python",
   "name": "python37664bitlewagonvenv87ffe36015ae4c2384279d21ffc66d52"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
